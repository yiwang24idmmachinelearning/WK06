{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshK8s21WBrf"
      },
      "source": [
        "# Week 06\n",
        "## Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf8SXUwWOho"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from image_utils import blur, edges, make_image, open_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## REVIEW:\n",
        "\n",
        "### Load image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Copy image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "same_img = himg.copy()\n",
        "display(same_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Update pixels in image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fimg = open_image(\"./data/flowers.jpg\")\n",
        "himg.update_pixels(fimg.pixels)\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create image from pixel list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_img = make_image(himg.pixels, fimg.size[0], fimg.size[1])\n",
        "display(new_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg.save(\"./data/newhog.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "newpxs = []\n",
        "for r,g,b in himg.pixels:\n",
        "  newpxs.append((b, r, g))\n",
        "\n",
        "himg.update_pixels(newpxs)\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "newpxs = [(g, b, r) for r,g,b in himg.pixels]\n",
        "himg.update_pixels(newpxs)\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RGB to grayscale\n",
        "\n",
        "We can also remove colors by making the pixel have a single value equal to the average of its original RGB values.\n",
        "\n",
        "$\\displaystyle average = \\frac{R + G + B}{3}$\n",
        "\n",
        "This is a good way to estimate the luminosity of each pixel: brighter pixels will be white and darker pixels will be black."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "bwpxs = []\n",
        "for r,g,b in himg.pixels:\n",
        "  gval = (r + g + b) // 3\n",
        "  bwpxs.append(gval)\n",
        "\n",
        "himg.update_pixels(bwpxs)\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Non-homework assignment\n",
        "\n",
        "<img src=\"./imgs/red-coat-filter.jpg\" width=\"720px\">\n",
        "\n",
        "The logic could be something like: if pixel is red, keep it, otherwise turn into greyscale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fimg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "fpxs = []\n",
        "for r,g,b in fimg.pixels:\n",
        "  if (r - b) > 140 and (g - b) > 100:\n",
        "    fpxs.append((r, g, b))\n",
        "  else:\n",
        "    gv = (r + g + b) // 3\n",
        "    fpxs.append((gv, gv, gv))\n",
        "\n",
        "fimg.update_pixels(fpxs)\n",
        "display(fimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filtering by Color\n",
        "\n",
        "Let's formalize what we mean by filtering and be a bit more precise with what we are trying to do.\n",
        "\n",
        "Let's say we're working on a vegetation detector and we want to be able to separate the pixels that represent plants and flowers from pixels that represent animals and other things.\n",
        "\n",
        "We can start by creating a filter to separate the green pixels from our original image.\n",
        "\n",
        "This is different than looking at the `green` color channel, or removing the `red` and `blue` channels, or exaggerating the green pixels.\n",
        "\n",
        "In order to filter pixels of a certain color we have to go through the pixels and measure how similar they are to the color we wish to separate.\n",
        "\n",
        "There are many ways to define \"similar\" when working with colors, but to keep it simple, let's define a `color_distance()` function that calculates the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between two colors:\n",
        "\n",
        "$\\displaystyle dist = \\sqrt{\\left(R_0 - R_1\\right)^2 + \\left(G_0 - G_1\\right)^2 + \\left(B_0 - B_1\\right)^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def color_distance(c0, c1):\n",
        "  return ((c0[0] - c1[0])**2 + (c0[1] - c1[1])**2 + (c0[2] - c1[2])**2) ** 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing pixels\n",
        "\n",
        "Now that we have a function for measuring color similarity we can go through the pixels and remove the ones that are very different from the color we want to keep. We'll remove pixels by turning them black with RGB value (0, 0, 0).\n",
        "\n",
        "Since we're making some pretty significant changes to our image, let's keep a copy of the original. We can do this by just calling the `copy()` member function of an image object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "fimg = himg.copy()\n",
        "\n",
        "keep_color = (20, 180, 20)\n",
        "thold = 120\n",
        "\n",
        "filtpxs = []\n",
        "for r,g,b in himg.pixels:\n",
        "  if color_distance((r, g, b), keep_color) < thold:\n",
        "    filtpxs.append((r, g, b))\n",
        "  else:\n",
        "    filtpxs.append((0, 0, 0))\n",
        "\n",
        "fimg.update_pixels(filtpxs)\n",
        "\n",
        "display(himg)\n",
        "display(fimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter other colors\n",
        "\n",
        "How can we filter the image to keep only the flowers? Or to keep only the hedgehog?\n",
        "\n",
        "It might help to define a `filter_color()` function here that takes an image and a color to keep as inputs, and returns another image with just the kept pixels ... while keeping the original image intact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: filter image to keep only flowers then filter image to keep only hedgehog\n",
        "\n",
        "def filter_color(img, keep_color, thold=150):\n",
        "  # TODO: fill this in\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vegetation Filter\n",
        "\n",
        "Now, what we actually want is to separate the image into two images, one with the hedgehog and another with the vegetation.\n",
        "\n",
        "There are a couple of ways to achieve this.\n",
        "\n",
        "One way to get the vegetation pixels in this case is to remove the hedgehog from the original image. We can do this by first getting the hedgehog pixels and then subtracting them from the original image, pixel by pixel, component by component.\n",
        "\n",
        "We can use the `zip()` function to iterate through both pixel arrays at the same time and subtract their components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "hog_img = filter_color(himg, (200,200,200), 200)\n",
        "\n",
        "veget_pxs = []\n",
        "for (r0,g0,b0), (r1,g1,b1) in zip(himg.pixels, hog_img.pixels):\n",
        "  veget_pxs.append((r0-r1, g0-g1, b0-b1))\n",
        "\n",
        "himg.update_pixels(veget_pxs)\n",
        "display(himg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤔\n",
        "\n",
        "This is ok.\n",
        "\n",
        "The other way to separate the vegetation is to filter the green pixels into an array, then filter the yellow pixels into another array, and then add them together, pixel by pixel, component by component.\n",
        "\n",
        "This works because we made the pixels we don't want black, or (0, 0, 0), so we can add green or yellow pixels to black without changing their color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get a pixel array for the green pixels\n",
        "# TODO: get a pixel array for the yellow pixels\n",
        "\n",
        "# TODO: add green and yellow pixel arrays\n",
        "#       zip() can help\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🎉\n",
        "\n",
        "### Counting pixels by colors\n",
        "\n",
        "Now that we can separate pixels by color, we could use it to create an automatic deforestation sensor by separating and counting green pixels, and calculating the percentage of green areas on images.\n",
        "\n",
        "We could implement a separate function to count the number of non-black pixels in an image after it has been filtered, but since our `filter_color()` function above already goes through all of the pixels in an image and detects pixels of specific colors, we can just create a modified version of it that counts those pixels and returns the ratio relative to the total number of pixels, instead of returning a filtered image.\n",
        "\n",
        "We can call this new function `color_ratio()` and it will take and image, a color and a threshold as parameters, like the `filter_color()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: create color_ratio() function\n",
        "\n",
        "def color_ratio(img, keep_color, thold=150):\n",
        "  # TODO: modify the content of the filter_color() function\n",
        "  return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can try it out on a couple of forest images inside the `data/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fimg = open_image(\"./data/forest-00.jpg\")\n",
        "display(fimg)\n",
        "\n",
        "ffimg = filter_color(fimg, (0,200,0), 180)\n",
        "display(ffimg)\n",
        "\n",
        "green_ratio = color_ratio(fimg, (0,200,0), 180)\n",
        "print(f\"green %: {round(100 * green_ratio, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try it out on some other images\n",
        "\n",
        "There are $6$ other aerial forest images in the `data/` directory. Run the green pixel count code on them and see if the results make sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: count green pixels in forest images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we start doing image analysis it's good to be able to extract different kinds of information from our images in case we want to categorize them, filter them further or retrieve them from large databases later.\n",
        "\n",
        "This is kind of equivalent to how we extracted amplitude and frequency features from audio files.\n",
        "\n",
        "### Dominant Channel\n",
        "\n",
        "One feature we can easily extract from our images is the average value of each of its channels along with the average luminosity value.\n",
        "\n",
        "This can be used to give us some idea about the dominant color or tones in an images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "# array with 4 0s\n",
        "hog_rgbl_sum = 4 * [0]\n",
        "\n",
        "for r,g,b in himg.pixels:\n",
        "  l = (r + g + b) // 3\n",
        "  hog_rgbl_sum[0] += r\n",
        "  hog_rgbl_sum[1] += g\n",
        "  hog_rgbl_sum[2] += b\n",
        "  hog_rgbl_sum[3] += l\n",
        "\n",
        "hog_rgbl_avg = [s // len(himg.pixels) for s in hog_rgbl_sum]\n",
        "\n",
        "hog_rgbl_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that both the `green` and `red` channels have average values above the average luminosity value.\n",
        "\n",
        "This makes sense since the image has a lot of green pixels, and the `red` channel contributes to the yellow and white pixels.\n",
        "\n",
        "### Repeat for other image\n",
        "\n",
        "Get the average value for each channel of a different image.\n",
        "\n",
        "Maybe create a function...\n",
        "\n",
        "Does the result make sense?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get average channel value for other image\n",
        "\n",
        "def get_channel_avgs(pxs):\n",
        "  # TODO: fill this in\n",
        "  return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: run function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Color Histograms\n",
        "\n",
        "Color histograms are another useful method of analyzing images and extracting information about their color.\n",
        "\n",
        "A histogram is just a concise way of seeing how many pixels have particular channel values. We'll go through an image's pixel array and count how many pixels have a $0$ for the `red` channel, how many have a $1$, a $2$, $3$, etc... and then we'll repeat this for the `green` and `blue` channels and for luminance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "himg = open_image(\"./data/hog.jpg\")\n",
        "\n",
        "# create 4 arrays (RGB + luminance) with 255 0s, one for each possible value a pixel component can have\n",
        "hog_hist_cnts = [256 * [0] for p in range(4)]\n",
        "\n",
        "for r,g,b in himg.pixels:\n",
        "  l = (r + g + b) // 3\n",
        "  hog_hist_cnts[0][r] += 1\n",
        "  hog_hist_cnts[1][g] += 1\n",
        "  hog_hist_cnts[2][b] += 1\n",
        "  hog_hist_cnts[3][l] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(hog_hist_cnts[0], 'r')\n",
        "plt.plot(hog_hist_cnts[1], 'g')\n",
        "plt.plot(hog_hist_cnts[2], 'b')\n",
        "plt.plot(hog_hist_cnts[3], color='#aaa')\n",
        "plt.ylim((0, 10000))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get histogram for flower image\n",
        "\n",
        "Maybe create some functions ... that can be reused later..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat process and draw histogram for flowers picture\n",
        "\n",
        "def get_hist_counts(pxs):\n",
        "  # TODO: fill this in\n",
        "  return []\n",
        "\n",
        "def plot_hist(rgbl_cnt, ylim=None):\n",
        "  # TODO: fill this in\n",
        "  plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: test functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing histograms\n",
        "\n",
        "Even though histograms can't by themselves tell us about the content of an image, comparing the most-frequent channel values in different images can tell us something about the images.\n",
        "\n",
        "Let's get the most frequent value of each channel.\n",
        "\n",
        "We'll do this by sorting `(value, count)` pairs by `count`.\n",
        "\n",
        "And, we can get `(value, count)` pairs for our lists by simplify using the `enumerate()` function since the `value` here is the same as the index for each list.\n",
        "\n",
        "Let's create a function to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_most_frequent(hist_counts):\n",
        "  # to sort by the second element of an array or tuple\n",
        "  def byCount(A):\n",
        "    return A[1]\n",
        "\n",
        "  # sort (value, count) pairs by count for each of the 4 histogram lists\n",
        "  sorted_rgbl_cnt = [sorted(enumerate(hl), key=byCount, reverse=True) for hl in hist_counts]\n",
        "\n",
        "  # grab the first element of the first (value, count) pair of each list\n",
        "  top_rgbl = [shl[0][0] for shl in sorted_rgbl_cnt]\n",
        "\n",
        "  return top_rgbl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_most_frequent(hog_hist_cnts), get_most_frequent(flo_hist_cnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤔\n",
        "\n",
        "What this tells us is that the hedgehog image is generally darker (all channel values and luminance are less than $100$) and `green` is possibly the brightest channel.\n",
        "\n",
        "The flower picture is bright (luminance above $200$) and there are more bright `red` tones than any other tones.\n",
        "\n",
        "But besides these easily interpretable descriptions, there's a lot of information in this data that might not be obvious to us if we're only looking at $1$ or $2$ images.\n",
        "\n",
        "A color histogram is another example of a transformation that encodes/compresses the information in the original data into less numbers, while keeping some significant information about it.\n",
        "\n",
        "In this case, information about an image with $600,000$ pixels and $3$ channels ($1,800,000$ values) is being represented by $4$ lists of $256$ numbers.\n",
        "\n",
        "### Repeat with other images\n",
        "\n",
        "Plot histograms and get the average and most frequent channel values for $2$ other images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: repeat histogram for other images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Edge Detection\n",
        "\n",
        "We've looked at some techniques for getting color information from images, but images are more than just colors.\n",
        "\n",
        "We might be interested in also quantifying the shapes and textures present in our images.\n",
        "\n",
        "We can start by extracting the edges of shapes in our image. There are many ways of doing this, but the simplest way is to subtract our original image from a blurry version of it and threshold the result.\n",
        "\n",
        "Since we are not so concerned with color at this point we should work with grayscale images.\n",
        "\n",
        "Our overall algorithm will be something like:\n",
        "- open an image\n",
        "- make it black & white\n",
        "- blur it\n",
        "- subtract the blurry b&w pixels from the original b&w pixels\n",
        "- threshold the result\n",
        "\n",
        "Threshold means making slightly bright pixels really bright and all other pixels really dark.\n",
        "\n",
        "Let's do this in steps:\n",
        "\n",
        "#### Open an image and extract its pixels\n",
        "\n",
        "We can use the `open_image()` function and the `pixels` member variable to open and extract pixels, and `display()` to show the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement edge extraction algorithm\n",
        "  # open an image and extract its pixels\n",
        "\n",
        "mimg = ''''''\n",
        "ipxs = ''''''\n",
        "\n",
        "display(mimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Blur the image using `blur()`\n",
        "\n",
        "And display it.\n",
        "\n",
        "The `blur()` function takes an image object as a parameter and an optional second parameter that specifies the amount of blurring. It returns another image object.\n",
        "\n",
        "Experiment with the parameter a little bit, but the default value is good for extracting edges.\n",
        "\n",
        "Let's also get the pixels for the blurred image and display it with `display()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement edge extraction algorithm\n",
        "  # blur image with the blur() function\n",
        "\n",
        "bimg = ''''''\n",
        "bpxs = ''''''\n",
        "\n",
        "display(bimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Make the images grayscale\n",
        "\n",
        "We saw this a few cells back. We can average the `RGB` values to get a grey luminance value.\n",
        "\n",
        "Get grayscale versions of the original image and the blurry image\n",
        "\n",
        "Display the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement edge extraction algorithm\n",
        "  # make the image b&w\n",
        "\n",
        "bwimg = mimg.copy()\n",
        "bwbimg = bimg.copy()\n",
        "\n",
        "# TODO: make b&w\n",
        "bwpxs = ''''''\n",
        "bwbpxs = ''''''\n",
        "\n",
        "bwimg.update_pixels(bwpxs)\n",
        "display(bwimg)\n",
        "\n",
        "bwbimg.update_pixels(bwbpxs)\n",
        "display(bwbimg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Subtract the blurred pixels from the original pixel values\n",
        "\n",
        "The `zip()` function might help iterate through the pixel arrays from both images at the same time.\n",
        "\n",
        "Display the resulting image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement edge extraction algorithm\n",
        "  # subtract blurry b&w image from original b&w image\n",
        "\n",
        "simg = bwpxs.copy()\n",
        "\n",
        "# TODO: subtract bwbpxs from bwpxs\n",
        "spxs = ''''''\n",
        "\n",
        "simg.update_pixels(spxs)\n",
        "display(simg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Threshold the resulting pixel values\n",
        "\n",
        "We'll go through the array and check each pixel:<br>\n",
        "if its luminance is greater than a threshold value, we'll make it $255$, otherwise we'll make it $0$.\n",
        "\n",
        "We can start with a threshold value of $16$ and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement edge extraction algorithm\n",
        "  # threshold pixel values\n",
        "\n",
        "timg = simg.copy()\n",
        "\n",
        "# TODO: threshold pixels\n",
        "tpxs = ''''''\n",
        "\n",
        "timg.update_pixels(tpxs)\n",
        "display(timg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great !\n",
        "\n",
        "### Let's repeat it for a different image\n",
        "\n",
        "First, create a function that takes an image as a parameter and returns another image with edge information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: create edge extraction function\n",
        "\n",
        "def edges(img, rad=1, thold=16):\n",
        "  # TODO: fill this in\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: use function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count edges\n",
        "\n",
        "It helps to have a single value that we can use to compare edge information between images.\n",
        "\n",
        "Let's create a function that counts the number of white pixels in an edge-extraction image.\n",
        "\n",
        "We'll divide this number by the number of pixels in the image to get a rough idea of how _edgy_ any image is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def edge_ratio(img, rad=1, thold=16):\n",
        "  eimg = edges(img, rad=rad, thold=thold)\n",
        "  sum255 = sum([1 for rgb in eimg.pixels if rgb[0] == 255])\n",
        "  npxs = len(eimg.pixels)\n",
        "  return round(sum255 / npxs, 4)\n",
        "\n",
        "mimg = open_image(\"./data/hog.jpg\")\n",
        "display(edges(mimg, 2))\n",
        "edge_ratio(mimg, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count edges for different images\n",
        "\n",
        "Do the results make sense? Why did we divide the sum by the total number of pixels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: run the edge_ratio() function on a few images"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.17 ('hf-model')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "89e384cab7c47fb35ec95d2248b519cf922ee174880eed636c26cdfb6c4df768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
